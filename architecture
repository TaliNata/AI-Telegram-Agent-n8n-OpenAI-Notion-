# Общий обзор

Агент построен по event-driven архитектуре с двумя точками входа:
Interactive mode — пользователь пишет боту в Telegram
Scheduled mode — агент запускается по расписанию (Cron)
Обе ветки сходятся в единый LLM-pipeline, который:
Получает контекст
Формирует prompt
Генерирует ответ через LLM
Отправляет результат в Telegram
Логирует результат в Notion

## Точки входа (Triggers)

Telegram Trigger
Срабатывает на входящее сообщение
Используется для:
команд (/start, /digest, и т.д.)
свободного пользовательского текста
Передаёт message, chat_id, user_id, text

## Schedule Trigger (Cron)

Запуск по расписанию (например, ежедневный дайджест)
Не требует пользовательского ввода


## Pre-processing слой (Контекст и валидация)
 IF /start
Проверка: является ли сообщение командой /start
Если да → onboarding-цепочка

## Welcome Message → Send Welcome

Отдельная ветка приветствия
Не затрагивает основной LLM-pipeline
Улучшает UX и снижает нагрузку на модель

## Extract Telegram Data

Нормализация входных данных:
очистка текста
извлечение chat/user metadata
Приведение формата к единому ctx

## Prepare Cron Context

Создаёт псевдо-сообщение:
command
source = cron
временной диапазон
Позволяет использовать тот же pipeline, что и для Telegram

## Command & Context Layer
Validate Command

Центральный узел маршрутизации логики
Определяет:
тип сценария (чат / дайджест / аналитика)
допустимость команды

Защищает LLM от мусорного или некорректного ввода

## Data Layer (Notion)
### Fetch Notion Records

Получение данных из Notion:
новости
записи
накопленный контекст

Может возвращать batch (до 50 items)

Используется как:
источник фактов
memory-storage
база для дайджестов

## Prompt Engineering Layer
### Build Prompt

Ключевой интеллектуальный узел

Собирает:
команду / задачу
данные из Notion
системные инструкции
Формирует детерминированный prompt, а не “сырой текст”

## LLM Layer
###OpenAI Chat Model

Подключён как модель

Используется через:
### Basic LLM Chain

Обеспечивает:
повторяемость
контроль входа/выхода
возможность смены модели без переписывания логики

## Post-processing & Output
###Prepare Telegram Message

Форматирование ответа:
Markdown / plain text
лимиты Telegram

Очистка и структурирование LLM-ответа
Send Telegram Message

Отправка результата пользователю
Единый выход как для Cron, так и для чата

## Observability & Logging
### Log to Notion

Запись:
входного контекста
результата LLM
timestamp
source (telegram / cron)

Используется для:

аудита
аналитики
улучшения prompt-ов

## Error Handling (отдельный контур)
### Error Trigger

Глобальный перехват ошибок workflow

### Format Error Data

Приведение ошибки к читаемому виду:

workflow
node
stack
timestamp

### Send Error Alert (Telegram)

Уведомление владельца/разработчика
Позволяет реагировать без доступа к n8n UI

##  Архитектурные принципы

Single pipeline для Telegram и Cron
Separation of concerns (триггеры / логика / LLM / логирование)
LLM-agnostic (модель можно заменить)

✅ Observability by default

✅ Production-ready error handling
